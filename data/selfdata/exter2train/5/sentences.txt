We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
in a prepositional phrase.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
coreferential) relations.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
A monotone phrasal decoder generates contextual replacements.
We propose a kana-kanji conversion system with input support based on prediction.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
idf based method.
coreferential) relations.
block bigram features.
This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We describe an implementation of a hybrid statistical/symbolic approach to repairing parser failures in a speech-to-speech translation system.
idf based method.
(Unification Categorial Grammar).
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a scheme for efficiently representing a lexicalized tree-adjoining grammar (LTAG).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We propose a kana-kanji conversion system with input support based on prediction.
Unification-based grammar formalisms use structures containing sets of features to describe linguistic objects.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
A monotone phrasal decoder generates contextual replacements.
statistical lexical head- outward transducers.
We propose a kana-kanji conversion system with input support based on prediction.
(Unification Categorial Grammar).
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
We develop a Data-Oriented Parsing (DOP) model based on the syntactic representations of Lexical- Functional Grammar (LFG).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We propose a distribution-based pruning of n-gram backoff language models.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
statistical lexical head- outward transducers.
We propose a kana-kanji conversion system with input support based on prediction.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
We investigated the applicability of probabilistic context-free grammars to syllabification and grapheme-to-phoneme conversion.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We propose a distribution-based pruning of n-gram backoff language models.
(Unification Categorial Grammar).
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
We train a segmenter and a tagger model separately based on linear-chain Conditional Random Fields (CRF), using lexical, morphological and semantic features.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
(Unification Categorial Grammar).
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
in content based information retrieval.
We propose a method for semi-automatic classi-fication of verbs to Levin classes via the seman-tic network of WordNet.
This paper presents a maximum entropy-based named entity recognizer (NER).
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
coreferential) relations.
This paper presents a generalized unknown morpheme handling method with POSTAG(POStech TAGger) which is a statistical/rule based hybrid POS tagging system.
(Unification Categorial Grammar).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
This paper discusses the partitive-genitive case alternation of Finnish adpositions.
This paper describes machine learning based parsing and question classification for question answering.
We propose a kana-kanji conversion system with input support based on prediction.
This paper proposes an error-driven HMM-based text chunk tagger with context-dependent lexicon.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present experiments training log-linear combinations of models for dependency parsing and for machine translation.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
statistical lexical head- outward transducers.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We propose a kana-kanji conversion system with input support based on prediction.
coreferential) relations.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
in content based information retrieval.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a discriminative, large- margin approach to feature-based matching for word alignment.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We propose a method for semi-automatic classi-fication of verbs to Levin classes via the seman-tic network of WordNet.
A monotone phrasal decoder generates contextual replacements.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
statistical lexical head- outward transducers.
We present a novel disambiguation method for unification-based grammars (UBGs).
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs).
We present BAYESUM (for 揃ayesian summarization?, a model for sentence extraction in query-focused summarization.
(Unification Categorial Grammar).
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a scheme for efficiently representing a lexicalized tree-adjoining grammar (LTAG).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs).
(Unification Categorial Grammar).
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
This paper describes machine learning based parsing and question classification for question answering.
We propose a kana-kanji conversion system with input support based on prediction.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a joint inference model to improve Chinese name tagging by incorporating feedback from subsequent stages in an information extraction pipeline: name structure parsing, cross-document coreference, semantic relation extraction and event extraction.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
(Unification Categorial Grammar).
We present a discriminative, large- margin approach to feature-based matching for word alignment.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
This paper describes discriminative language modeling for a large vocabulary speech recognition task.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
A monotone phrasal decoder generates contextual replacements.
This paper presents a maximum entropy-based named entity recognizer (NER).
We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs).
We propose a method for compiling bilingual terminologies of multi-word terms (MWTs) for given translation pairs of seed terms.
idf based method.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present experiments training log-linear combinations of models for dependency parsing and for machine translation.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
This paper introduces PhraseNet, a context- sensitive lexical semantic knowledge base system.
We propose a kana-kanji conversion system with input support based on prediction.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We propose a distribution-based pruning of n-gram backoff language models.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We present a joint inference model to improve Chinese name tagging by incorporating feedback from subsequent stages in an information extraction pipeline: name structure parsing, cross-document coreference, semantic relation extraction and event extraction.
in a prepositional phrase.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe an automatic Word Sense Disambiguation (WSD) system that disambiguates verb senses using syntactic and semantic features that encode information about predicate arguments and semantic classes.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
We propose a kana-kanji conversion system with input support based on prediction.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
This paper describes log-linear parsing models for Combinatory Categorial Grammar (CCG).
(Unification Categorial Grammar).
We introduce CST (cross-document structure theory), a paradigm for multi-document analysis.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
in a prepositional phrase.
We describe an automatic Word Sense Disambiguation (WSD) system that disambiguates verb senses using syntactic and semantic features that encode information about predicate arguments and semantic classes.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We propose a kana-kanji conversion system with input support based on prediction.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
This paper presents a maximum entropy-based named entity recognizer (NER).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
We propose a distribution-based pruning of n-gram backoff language models.
idf based method.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
We present a discriminative, large- margin approach to feature-based matching for word alignment.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
(Unification Categorial Grammar).
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
A monotone phrasal decoder generates contextual replacements.
block bigram features.
We propose a distribution-based pruning of n-gram backoff language models.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
We describe an implementation of a hybrid statistical/symbolic approach to repairing parser failures in a speech-to-speech translation system.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
In this paper we tackle sentence boundary disam-biguation through a part-of-speech (POS) tagging framework.
(Unification Categorial Grammar).
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
coreferential) relations.
This paper discusses the partitive-genitive case alternation of Finnish adpositions.
We describe experiments learning quasi-synchronous context-free grammars from bitext.
idf based method.
block bigram features.
in a prepositional phrase.
statistical lexical head- outward transducers.
statistical lexical head- outward transducers.
idf based method.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We investigated the applicability of probabilistic context-free grammars to syllabification and grapheme-to-phoneme conversion.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We propose a kana-kanji conversion system with input support based on prediction.
(Unification Categorial Grammar).
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
In this paper we tackle sentence boundary disam-biguation through a part-of-speech (POS) tagging framework.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a learning-based method to identify single-snippet answers to definition questions in question answering systems for document collections.
We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars (LFG) to the domain of sentence condensation.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
block bigram features.
(Unification Categorial Grammar).
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
idf based method.
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
block bigram features.
We perform Noun Phrase Bracketing by using a local, maximum entropy-based tagging model, which produces bracketing hypotheses.
(Unification Categorial Grammar).
We also associate this prosodic model with orthographic and part-of-speech analyses of cue phrases in text.
(Unification Categorial Grammar).
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
statistical lexical head- outward transducers.
We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs).
(Unification Categorial Grammar).
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
This paper presents a maximum entropy-based named entity recognizer (NER).
coreferential) relations.
This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules.
in a prepositional phrase.
We propose a kana-kanji conversion system with input support based on prediction.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We propose to score phrase translation pairs for statistical machine translation using term weight based models.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We propose a kana-kanji conversion system with input support based on prediction.
We propose to score phrase translation pairs for statistical machine translation using term weight based models.
idf based method.
A monotone phrasal decoder generates contextual replacements.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
We present a corpus-based study of the sequential ordering among premodifiers in noun phrases.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
A monotone phrasal decoder generates contextual replacements.
This paper discusses the partitive-genitive case alternation of Finnish adpositions.
coreferential) relations.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
A monotone phrasal decoder generates contextual replacements.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
This paper describes discriminative language modeling for a large vocabulary speech recognition task.
This paper introduces PhraseNet, a context- sensitive lexical semantic knowledge base system.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
in content based information retrieval.
We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars (LFG) to the domain of sentence condensation.
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
in content based information retrieval.
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
statistical lexical head- outward transducers.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
A monotone phrasal decoder generates contextual replacements.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
statistical lexical head- outward transducers.
(Unification Categorial Grammar).
idf based method.
coreferential) relations.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
In this paper I outline Type-inheritance Combinatory Categorial Grammar (TCCG), an implemented feature structure based CCG fragment of English.
This paper describes machine learning based parsing and question classification for question answering.
(Unification Categorial Grammar).
We present an application of ambiguity packing and stochastic disambiguation techniques for Lexical-Functional Grammars (LFG) to the domain of sentence condensation.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
A monotone phrasal decoder generates contextual replacements.
We propose a kana-kanji conversion system with input support based on prediction.
This paper proposes a bidirctional hierarchical clustering algorithm for simultaneously clustering words of different parts of speech based on collocations.
We develop a Data-Oriented Parsing (DOP) model based on the syntactic representations of Lexical- Functional Grammar (LFG).
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
in content based information retrieval.
A monotone phrasal decoder generates contextual replacements.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
This paper proposes a bidirctional hierarchical clustering algorithm for simultaneously clustering words of different parts of speech based on collocations.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
We propose a distribution-based pruning of n-gram backoff language models.
This paper describes discriminative language modeling for a large vocabulary speech recognition task.
We propose a kana-kanji conversion system with input support based on prediction.
We propose to score phrase translation pairs for statistical machine translation using term weight based models.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs).
We present a linguistically-motivated algorithm for reconstructing nonlocal dependency in broad-coverage context-free parse trees derived from treebanks.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
We describe experiments learning quasi-synchronous context-free grammars from bitext.
This paper describes machine learning based parsing and question classification for question answering.
in content based information retrieval.
A monotone phrasal decoder generates contextual replacements.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
