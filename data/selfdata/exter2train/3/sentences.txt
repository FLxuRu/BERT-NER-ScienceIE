We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This position paper contrasts rhetorical structuring of propositions with intentional decomposition using communicative acts.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
Syntax-based statistical machine translation (MT) aims at applying statistical models to structured data.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
in a prepositional phrase.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
coreferential) relations.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
The model uses syntactic patterns and N-grams reflecting the hierarchical discourse structures of dialogues.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
A monotone phrasal decoder generates contextual replacements.
We propose a kana-kanji conversion system with input support based on prediction.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
Unification-based grammar formalisms use structures containing sets of features to describe linguistic objects.
We introduce CST (cross-document structure theory), a paradigm for multi-document analysis.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
We describe experiments learning quasi-synchronous context-free grammars from bitext.
We propose a distribution-based pruning of n-gram backoff language models.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
This paper describes the incremental generation of parse tables for the LRtype parsing of Tree Adjoining Languages (TALs).
We investigated the applicability of probabilistic context-free grammars to syllabification and grapheme-to-phoneme conversion.
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
This paper describes a grapheme-to-phoneme conversion method using phoneme connectivity and CCV conversion rules.
We present a constraint-based case frame lexicon architecture for bi-directional mapping between a syntactic case frame and a semantic frame.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
This paper introduces PhraseNet, a context- sensitive lexical semantic knowledge base system.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
(Unification Categorial Grammar).
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
The HMM-LR algorithm uses a generalized LR parser as a language model and hidden Markov models (HMMs) as phoneme models.
We describe an automatic Word Sense Disambiguation (WSD) system that disambiguates verb senses using syntactic and semantic features that encode information about predicate arguments and semantic classes.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
statistical lexical head- outward transducers.
This paper introduces PhraseNet, a context- sensitive lexical semantic knowledge base system.
coreferential) relations.
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
idf based method.
(Unification Categorial Grammar).
We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts.
This paper describes a project tagging a spontaneous speech corpus with morphological information such as word segmentation and parts-ofspeech.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
Categorial unification grammars (CUGs) embody the essential properties of both unification and categorial grammar formalisms.
We propose a method of using associative	strength	among	morphemes,morpho-syntactic patterns, and syntactic categories to solve the ambiguities of segmentation and part-of-speech.
We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.
A monotone phrasal decoder generates contextual replacements.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
We compute frequencies of unigrams, bigrams, and trigrams of word classes in order to further refine the disambiguation.
in Machine Translation).
We present a constraint-based syntax-semantics interface for the construction of RMRS (Robust Minimal Recursion Semantics) representations from shallow grammars.
(Unification Categorial Grammar).
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
coreferential) relations.
(Unification Categorial Grammar).
We describe a corpus-based induction algorithm for probabilistic context-free grammars.
We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the- art constituency-based parsers.
In this paper I outline Type-inheritance Combinatory Categorial Grammar (TCCG), an implemented feature structure based CCG fragment of English.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We present experiments training log-linear combinations of models for dependency parsing and for machine translation.
We propose a syntax of it-clefts using Tree-Local Multi- Component Tree Adjoining Grammar and a compositional semantics on the proposed syntax using Synchronous Tree Adjoining Grammar.
The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.
Unification of disjunctive feature descriptions is important for efficient unification-based parsing.
The Hidden Markov Model (HMM) for part-of-speech (POS) tagging is typically based on tag trigrams.
We propose a paraphrasing model for LVCs that is based on transforming the Lexical Conceptual Structures (LCSs) of verbal elements.
